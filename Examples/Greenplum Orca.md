Greenplum Orca - это оптимизатор для СУБД Greenplum.

Он спроектирован быть отдельным, независимым компонентом, для того, чтобы была возможность добавить его в любую базу данных. Но на сегодняшний день известно только 2 СУБД, которые это делают: Greenplum и Apache HAWQ.
## Цели

1. Цель на производительность - пользователи хранят сотни петабайт данных
2. План должен быть корректным - в противном случае запрос будет выполняться слишком долго
3. Планировщик должен быть расширяемым, чтобы не пришлось постоянно обновляться с мажорных версий Postgres

## Общее представление

Планировщик построен на основе фреймворка Cascades и использует Top-Down подход.

Он спроектирован таким образом, чтобы быть независимым от конкретной СУБД и мог использоваться как самостоятельный компонент. Для этого он использует фреймворк DXL - Data Exchange Language - диалект XML:
- DXL Query - представление исходного запроса, подается на вход
- DXL MD (MetaData) - представление метаданных (например, системный каталог или статистика), используется для получения дополнительной информации в процессе работы
- DXL Plan - представление плана выполнения, отправляется на выход хостовой СУБД

## Компоненты

### Memo

Основа фреймворка Cascades - Memo table. Это структура данных, содержащая Group - множество логически эквивалентных выражений и подцели (sub-goal), например, дополнительные фильтры таблицы.

Благодаря тому, что в Group содержатся все логически эквивалентные выражения, оптимизатор может обойти все пространство возможного выполнения запроса.

### Job scheduler

Это компонент, отвечающий за планирование выполнений Optimization Jobs - маленьких независимых задач оптимизации выражений.

Он должен утилизировать все доступные мощности (в частности, ядра процессора) для максимальной параллелизации работы.

### Transformations

Альтернативные планы создаются с помощью применения правил трансформации (Transformation rule) - они создают либо логически эквивалентные планы запроса (Tree->Tree), либо физические планы запроса (Tree->Plan).

После применения правила мы можем либо создать новую Group, либо добавить новое выражение к существующей Group.

Все результаты их работы сохраняются в Memo table, чтобы далее можно было получить уже вычисленное выражение.

Каждое правило самодостаточно и может быть включено/выключено через конфигурацию.

### Property

Для поддержки расширяемости план должен уметь подстраиваться под конкретный движок выполнения. Это выполняется с помощью механизма свойств (Property).

Всего существует 3 типа свойств:
- Логические - столбцы на выходе
- Физические - сортировка или распределение данных по разным узлам
- Скалярные - столбцы, используемые в JOIN'ах

Эти свойства назначаются оператором своим дочерним узлам и есть 2 исхода:
1. Дочерний узел выполняет это свойство (IndexScan может вернуть данные в отсортированном порядке)
2. Добавляется специальный оператор, который это свойство реализует (явный узел для сортировки) - enforcer

### Кэш метаданных

Так как метаданные хранятся в хостовой СУБД, то выполнять постоянные запросы к ней будет накладно. Это решается тем, что Orca кэширует полученные метаданные.

### GPOS

GPOS - GreenPlum OS - уровень абстракции над ОС, предоставляющий интерфейс управления ресурсами: память, примитивы синхронизации, обработка исключений, файловый IO и т.д.

## Алгоритм работы

Оптимизация выстроена в несколько этапов:

1. Pre-Processing (Step 0) - упрощение/нормализация
	1. Удаление излишних операций (Limit, Distinct, Равенства/Сравнения)
	2. Выравнивание AND/OR/NOT
	3. Вывод предикатов из равенств
	4. Нормализация скалярных выражений
	5. Выравнивание скалярных подзапросов
	6. Переписывание IN подзапрос в EXISTS с предикатом
2. Exploration (Step 1) - Logical -> Logical
	1. В процессе этого этапа создаются новые Group, которые добавляются в Memo
	2. В конце имеется уже готовое пространство возможных планов выполнения запроса
3. Statistics Derivation (Step 2) - делаем запросы хостовой СУБД
	1. В основном используются только гистограммы
	2. Вывод новой статистики производится только в Memo
	3. Для каждой группы статистику вычисляют/выводят по метрике Statistics Promise - специфична для каждого оператора
	4. Статистика собирается Bottom-Up подходом - при запросе статистики дочерних узлов они либо запрашивают ее у MD провайдера, либо у своих дочерних узлов
4. Implementation (Step 3) - Logical -> Physical
	1. Top-down проход
5. MPP Optimization (Step 4) - добавление Properties и подсчет стоимости
	1. Архитектура этого этапа похожа на исходный Cascades - для корневой группы вызываю Optimization Request, который рекурсивно проходит группы и вызывает Optimization Request уже для них.
	2. Optimization Request добавляет Enforcer'ы для поддержания требуемых свойств
	3. В процессе оптимизации одной и той же группе может поступить такой же Optimization Request, поэтому каждая группа хранит внутри себя хэш-таблицу этих запросов и при получении этого запроса вначале проверяет таблицу.

В процессе работы используется множество оптимизаций и эвристик. Примеры:
1. Join Ordering - используется несколько подходов: DP, Left-Deep Join Tree, Cardinality-based join ordering
2. Subquery decorrelation - использование декорреляции подзапросов
3. Partition Elimination - некоторые партиционированные таблицы могут быть отброшены во время работы (on-the-fly)
4. Common Expression - дорогие для вычисления выражения становятся CTE и уходят в WITH

### Распараллеливание

Нахождение лучшего плана запроса - это CPU-bound задача, поэтому возможность распараллеливания может дать значительный прирост производительности.

Планировщик разбивается на небольшие Unit-of-Work, которые называются Optimization Job:
- `Exp(group)` - Group Logical->Logical
- `Exp(groupExpr)` - Expression Logical->Logical
- `Imp(group)` - Group Logical->Physical
- `Imp(groupExpr)` - Expression Logical->Physical
- `Opt(group, req)` - Group best plan
- `Opt(groupExpr, req)` - Expression best plan
- `Xform(groupExpr, t)` - Expression transform

Можно заметить, что первые 4 соотносятся напрямую с трансформациями в Cascades. `Opt` - это нахождение лучшего плана запроса/выражения, а `Xform` - ???

В процессе выполнения составляется граф зависимостей - задача не сможет начать свое выполнение, пока не будут завершены все дочерние задачи. За планирование выполнения этих задач отвечает компонент Job Scheduler.
### Обмен метаданными

Orca спроектирован для работы вне СУБД, но при планировании запросов большую роль играют метаданные: индексы, статистика и т.д.

Для получения этой информации используются Metadata Providers - MD провайдер - специальный плагин, взаимодействующий с СУБД.

Когда необходимо получить ту или иную информацию выполняется запрос к СУБД через провайдер.

Имеется несколько оптимизаций:
1. Полученные метаданные кэшируются и перед отправкой запроса сначала просматривается кэш
2. Имеется специальный сборщик (harvester) метаданных из СУБД, которые по мнению Orca будут полезны. Они собираются в отдельные файлы, которые затем читает встроенный файловый MD провайдер.
## Тестирование

Orca проектировали с учетом тестируемости с самого начала.

В планировщик встроена своя схема тестирования:
1. Вначале запускаются встроенные регрессионные тесты. Они предназначены для обнаружения ошибок при изменении кода
2. Затем могут запускаться другие тесты, оценивающие разные аспекты планировщика, например, корректная оценка кардинальности.

## Поддержка

### AMPERe

AMPERe - Automatic capture of Minimal Portable and Executable Repors - это утилита, которая в случае ошибки выполнения создает дамп состояния для дальнейшего воспроизведения и отладки.

Так как СУБД выполняется на стороне клиента, то хранящиеся там данные не должны утечь во вне. Поэтому в этом дампе хранится минимальный слепок данных, который может помочь воспроизвести баг.

Этот дамп содержит:
- Данные для вопроизведения
- Состояние кэша MD провайдера
- Входной запрос
- Конфигурацию планировщика
- Метаданные в DXL формате

Этот инструмент также может использоваться для целей тестирования - каждый тест представлен таким дампом и на выходе мы должны получить корректный план.

### TAQO

TAQO - Testing the Accuracy of Query Optimizer - утилита для тестирования модели стоимости планировщика.

В ядре своем - это тестирование функции сортировки 2 планов в зависимости от их стоимости.

Алгоритм работы примерно следующий:
1. Выбираем подмножество (sample) возможных планов запроса
2. Получаем оценку их стоимостей
3. Выполняем и получаем настоящую стоимость
4. Ранжируем и вычисляем корреляцию оценок планов

## Источники

1. [Orca: A Modular Query Optimizer Architecture for Big Data](https://www.vmware.com/docs/white-paper-orca-a-modular-query-optimizer-architecture-for-big-data)
2. [Orca: A Modular Query Optimizer Architecture for VMware Greenplum (Venkatesh Raghavan)](https://www.youtube.com/watch?v=8NzvZ9X8inM&list=PLSE8ODhjZXjYPyrUG_YxqYPS7wjWY6gYN&index=10)

## Полезные идеи
1. Специальный файл, который позволит воспроизвести запрос - как для отладки, так и для тестирования