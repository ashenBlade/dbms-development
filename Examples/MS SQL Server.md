Описание работы планировщика SQL Server.

Источники:
1. [The Cascades Framework for Query Optimization at Microsoft (Nico Bruno + Cesar Galindo-Legaria)](https://www.youtube.com/watch?v=pQe1LQJiXN0&list=PLSE8ODhjZXjYPyrUG_YxqYPS7wjWY6gYN)
2. [Inside the SQL Server Query Optimizer](https://www.programmer-books.com/wp-content/uploads/2019/08/Inside-the-SQL-Server-Query-Optimizer.pdf)

## Общее описание
Планировщик запросов построен **на основании фреймворка Cascades**.

Запрос представляется с помощью **реляционной алгебры** (не сырое дерево запроса или компактное представление). После дополняется скалярными операторами (оператор, представляющий скаляр).

В процессе разработки заметили:
1. Большая часть времени работы уходит на проверки: шаблон запроса, свойства, предикаты и т.д.
2. DSL хорошо работает на простых кейсах, но когда логика становится сложной приходится работать с очень сложным DSL и учитывать множество правил
Поэтому все правила/трансформации пишут **напрямую на C++**.

Планировщик прошел несколько этапов "эволюции":
1. 1998 г. - первое внедрение в SQL Server
2. 2008 г. - используется в Cosmos/Scope (highly scalable relational processing)
3. 2010 г. - Parallel Data Warehouse (платформа анализа Big Data)
4. 2014 г. - используется в Polybase (federated database)
## Логика работы

Пайплайн оптимизации:

1. Parsing
	1. Парсинг запроса в дерево запроса
2. Algebrization
	1. Биндинг на системный каталог
	2. Семантические проверки
3. Simplification/Normalization
	1. Используются Transformation Rules
	2. Top-down/Bottom-up
	3. Canonicalize
	4. Общие правила, не требующие проверки стоимости:
		1. Subquery removal - превращение подзапросов в обычные JOIN
		2. Empty result pruning - обнаружение частей, которые ничего не вернут (например, `WHERE FALSE`)
		3. Outer to inner join - сведение `OUTER JOIN` к `INNER JOIN` (например, если есть `strict` (в терминах Postgres) предикат в `WHERE`)
		4. CUBE reduction (???)
		5. Redundant join removal - если для JOIN'а используется FOREIGN KEY и в ответе содержимое соединяемой таблицы не используется
		6. Predicate pushdown - опускаем предикаты как можно ближе к месту их использования
		7. Redundant GROUP BY via Functional dependency (???)
	5. Tree-to-Tree Transformation
	6. Не требуют использования memo
	7. Transformation rule, которые мы можем аннотировать как Simplification/Exploration Rule
	8. На выходе получаем "Initial tree"
	9. На практике этот этап дает большой выигрыш, т.к. позволяет быстро обнаружить оптимальный план и сократить пространство поиска
4. Pre-exploration
	1. Project normalization - опускаем Projection как можно глубже в дерево
		1. Это полезно, если есть COMPUTED COLUMN (SQL Server специфично)
	2. AutoStats - обнаружение столбцов, статистика по которым нам будет необходима для корректной cost-based оптимизации
		1. Если их нет, то можем собрать эту статистику (асинхронно, в фоне)
		2. Это может увеличить время получения первого кортежа (startup cost)
	3. Initial Cardinality Estimation (CE) - собираем кардинальность JOIN'ов
		1. Это выполняется с помощью предыдущего этапа сбора статистики
	4. Join collapsing - ???
	5. Trivial plan - если видим "тривиальный" план
		1. Тривиальный запрос - запрос, не зависящий от входных данных, то есть не нужно считать кардинальность и т.д. Для таких мы точно уверены, что можем сгенерировать оптимальный план сразу.
		2. Для такого запроса можем сразу сгенерировать оптимальный план
		3. Так как SQL Server - OLTP, то многие запросы заканчиваются здесь
		4. Примеры:
			1. `SELECT 1`
			2. `INSERT INTO`
			3. `SELECT ... FROM tbl` (только 1 таблица участвует)
5. Exploration
	1. Этапы
		1. Transaction Processing Phase (search 0) - пытаемся найти план как можно скорее без использования изощренных правил
			1. Подходит для OLTP систем
			2. Используется для запросов, использующих меньше 3 таблиц
			3. Тут генерируются изначальные JOIN'ы с самой большой селективностью
			4. Эвристика: соединяем наименьшие таблицы или таблицы, которые дают наибольшую селективность.
		2. Quick Plan (search 1)
			1. Вначале находим лучший последовательный план, а если под конец он плохой, то повторно ищем, но уже позволяем себе найти параллельные узлы
			2. 
		3. Full optimization (search 2) - непосредственно Cascades
	2. Очередной выполняется если предыдущий не смог сгенерировать оптимальный план, критерий - порог стоимости
	3. Полностью Cascades работает только на Full этапе
6. Post-optimization (engine specific, т.к. SQL Server может поддерживать множество различных движков)
	1. Common SubExpression (CSE) spools
	2. Unsorted scans
	3. Scalar evaluation placement
## Правила

В SQL Server существует больше 400 правил.

Hallowen Problem - решается с помощью свойства: UPDATE должен запрашивать физическое свойство на определенные столбцы. Дальше движок выдает список правил, которые должны быть выполнены.
Пример: `HashJoin` дает Halloween Protection, но `Nested Loop` может не давать.

Join enumeration - это тоже отдельное правило.

Примеры свойств:
- Contraint property (логическое свойство) - отслеживает равные столбцы (классы эквивалентности из Postgresql)

Transformation Rule делится на 3 подтипа:
1. Simplification - создает более простое дерево. Используется на этапе Simplification
2. Exploration (logical transformation rule) - создает логическое дерево эквивалентное старому (equivalent alternative)
3. Implementation (physical transformation rule) - получение физического дерева

Exploration и Implementation правила используются на этапе Full optimization.

Правила могут быть отключены с помощью хинтов. Но также можно с помощью отдельных стейтментов (например, `DBCC RULEOFF('RULENAME')`) их отключить на уровне всей системы (уточнить).



## Статистика

Используемые статистики:
- Single-column 'MaxDiff' гистограммы
- Multi-column density - сколько различных значений по группам столбцов
- Average column lengths - для столбцов переменной длины (varchar)
- Tries - подходит для строк (LIKE, CONTAINS)
- HyperLogLog/Heave Hitter sketches - для партиционированных таблиц
- Skew - для представления о содержимом партиций

Источники данных:

1. Таблицы (включая COMPUTED COLUMN)
2. Индексы
3. Материализованные представления

Механизм поддержки статистики/индексов:

1. Создание: ручное, автоматическое, неявное (при создании индекса у нас имеется статистика по префиксу этого индекса)
2. Обновление: ручное, автоматическое (отслеживаем количество обновлений)
3. Получение образцов (block-level sampling)

## Cardinality Estimation

Статистика передается/продвигается через операторы от таблиц (имеет статистику) выше. Например, выражение из `WHERE` обновило селективность, которая передается в `GROUP BY` с тем же столбцом.

Комбинированные предикаты вычисляются множеством стратегий:
- Skew
- Correlation
- С и без учета независимости
- Multi-Column Density

QOE (Quality Of Estimation) - правило, позволявшее понять, что оценка была достаточно точная, чтобы не прибегать к другим оценкам. Устаревшая реализация, которая может быть включена параметром `LEGACY_CARDINALITY_ESTIMATION`. Она использовала предположения:
1. Независимость предикатов - общая селективность вычислялась умножением всех селективностей
2. Равномерность распределения - в данных не было скосов
3. Простой принцип вложенности (Containment Simple) - ???
4. Принцип включения - запрашиваемые данные всегда существуют
В новой версии есть изменения:
5. Корреляция предикатов вместо независимости - предикаты коррелированы и могут выбирать те же самые данные
6. Базовый принцип вложенности вместо простого - пользователи могут запрашивать данные, которых нет

Новый фреймворк оценки кардинальности:
- Holistic calculators - оцениваются не отдельные предикаты, а целые фрагменты запроса
- Предположения теперь настраиваются через хинты (`ASSUME_JOIN_PREDICATE_DEPENDS_ON_FILTERS`)

Дополнительные техники:
1. Автопараметризация и исследование параметров
2. CE feedback

## Расчет стоимости

Расчет стоимости происходит в:
1. Bottom-up способе
	1. CPU и I/O стоимости
	2. Информация по операторам: кардинальность, размер строк, отсортированность, память, параллелизм
	3. Имеется 3 стоимости:
		1. Initial - первое выполнение запроса
		2. Rebind - в запросе участвует новый внешний параметр 
		3. Rewind - в запросе участвует уже использованный внешний параметр
	4. Initial >= Rebind >= Rewind - в памяти могли закешироваться предыдущие выполнения запроса
2. Top-down контекст используется
	1. Row goal
	2. Битмап фильтры
	3. Оцененное количество Rebind/Rewind

Только физические планы оцениваются (costed), так как одно и то же логическое дерево может иметь разные физические представления, и, соответственно, различную стоимость. 

## Optimization Performance

Cascades спроектирован в предположении обхода всей области решений. То есть все возможные альтренативные планы составить.
Это не совсем практично, поэтому необходимо иметь несколько оптимизаций.

Оптимизации:

1. Кэширование планов - храним готовые планы в кешэ и отдаем по необходимости
	1. Нужно учитывать валидность. Например, индекс удалили
2. Trivial plan
	1. Обнаруживаем простые планы и быстро их создаем
	2. Хорошая оптимизация для OLTP нагрузок
3. Отдельные этапы:
	1. На каждом этапе свой порог стоимости (+ таймаут) - применяем правила, пока не достигнем таймаута, а затем проверяем стоимость
	2. Постепенно увеличиваем множество доступных трансформаций
	3. Можно сделать настраиваемыми для каждого типа нагрузок
4. Memo seeding (good starting point)
	1. Сразу записываем в Memo-table начальные записи, например, методы доступа для таблиц (из которых и будем читать)
	2. Это может помочь на этапе Trivial Plan
	3. Можно заполнить (на основании эвристик для разных типов нагрузок (OLTP, OLAP...)):
		1. Таблицы
		2. Простые JOIN'ы
		3. JOIN'ы в изначальном дереве запроса (синтаксически как описано)
	4. Это можно делать не в единственном месте, а в разных
5. Gradual optimization
	1. Прекращаем применять оптимизации при достижении определенного порога (temperature-based)

## Тестирование

Тестирование необходимо производить в нескольких размерностях:
1. Корректность
2. Производительность
3. Размер плана
4. Потребляемая память
5. Ошибки CE

Откуда брать данные для тестов:
1. Бенчмарки (TPC-X)
2. Стохастическое/Фаззинг
3. Воспроизведение реальных нагрузок

С чем сверять:
1. Разные СУБД
2. Разные версии планировщика
3. С собой же

## Поддержка

В SQL Server имеются Dynamic Management Views (DMV) со статистикой планировщика `sys.dm_exec_query_optimizer_info`.
В нем расположено множество метрик планировщика - сколько оптимизаций было, сколько до каких этапов кто дошел, сколько раз достигали таймаутов и т.д.

Также, есть DMV для правил трансформаций `sys.dm_exec_query_transformation_stats`.

План запроса можно выгрузить в XML формате.

## Полезные идеи
1. Trivial plan - для OLTP систем многие запросы будут уходить сюда, поэтому этот путь надо оптимизировать
2. Хранить статистику планировщика и использовать ее для определения настроек под конкретную нагрузку (например, через VIEW, который обертка над функцией - состояние внутри будет находиться в общей памяти, а может и таблица прямо/свой файл как pgss)
3. Вместо того, чтобы идти через весь мой планировщик, можно придумать специальные правила, которые скажут использовать стандартный планировщик